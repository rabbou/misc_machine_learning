{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMSC 25025\n",
    "\n",
    "## Homework 3\n",
    "\n",
    "### Ruben Abbou\n",
    "\n",
    "### Problem 6: Stochastic gradient descent on beer reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, numpy as np, scipy as sp, sklearn, time\n",
    "import matplotlib.pyplot as plt, random\n",
    "from scipy.sparse import csr_matrix\n",
    "from numpy.linalg import norm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from math import exp, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/project2/cmsc25025/beer_review/labeled.json', 'r') as f:\n",
    "    brv = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_ratings = [d['overall'] for d in brv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean = 13.198880\n",
      "Median = 14.000000\n",
      "Standard Deviation = 3.352351\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean = %f\" % np.mean(overall_ratings))\n",
    "print(\"Median = %f\" % np.median(overall_ratings))\n",
    "print(\"Standard Deviation = %f\" % np.std(overall_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_ratings = {}\n",
    "brewer_ratings = {}\n",
    "for item in brv:\n",
    "    beer = item['beer_name']\n",
    "    brewer = item['brewer']\n",
    "    if beer not in beer_ratings.keys():\n",
    "        beer_ratings[beer] = []\n",
    "    if brewer not in brewer_ratings.keys():\n",
    "        brewer_ratings[brewer] = []\n",
    "    beer_ratings[beer].append(item['overall'])\n",
    "    brewer_ratings[brewer].append(item['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_stats = {k: [np.mean(v), np.median(v), np.std(v)] for k, v in beer_ratings.items()}\n",
    "brewer_stats = {k: [np.mean(v), np.median(v), np.std(v)] for k, v in brewer_ratings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example with PBR: \n",
      " Mean: 7.53\n",
      " Median: 7.00\n",
      " Standard Deviation: 4.67\n"
     ]
    }
   ],
   "source": [
    "pbr = beer_stats['Pabst Blue Ribbon']\n",
    "print('Example with PBR: \\n Mean: %.2f\\n' % pbr[0], 'Median: %.2f\\n' % pbr[1],\n",
    "      'Standard Deviation: %.2f' % pbr[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examplew with Brewer 5731: \n",
      " Mean: 6.85\n",
      " Median: 6.00\n",
      " Standard Deviation: 4.55\n"
     ]
    }
   ],
   "source": [
    "b1 = brewer_stats[5731]\n",
    "print('Examplew with Brewer 5731: \\n Mean: %.2f\\n' % b1[0], 'Median: %.2f\\n' % b1[1],\n",
    "      'Standard Deviation: %.2f' % b1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average beer rating sd: 1.33\n",
      " Average brewer rating sd: 2.09\n"
     ]
    }
   ],
   "source": [
    "beer_sd = [v[2] for v in beer_stats.values()]\n",
    "brewer_sd = [v[2] for v in brewer_stats.values()]\n",
    "print('Average beer rating sd: %.2f\\n'%np.mean(beer_sd),\n",
    "      'Average brewer rating sd: %.2f'%np.mean(brewer_sd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average standard deviations are 1.33 and 2.09, which can be considered pretty high since some beers only have one review and no standard deviation. In general, it looks like people have very different opinions about beers, which makes sense because people's tastes vary a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "### (a) *Generating features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/project/cmsc25025/beer_review/vocab_30.json', 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(brv)\n",
    "training = brv[:int(.7*L)]\n",
    "validation = brv[int(.7*L):int(.85*L)]\n",
    "testing = brv[int(.85*L):]\n",
    "keys = list(vocab.keys())\n",
    "sample = {k:0 for k in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sparse_matrix(vocab, reviews, rating_type):\n",
    "    '''\n",
    "    takes reviews as inputs\n",
    "    returns sparse matrix of words, and labels\n",
    "    '''\n",
    "    keys = list(vocab.keys())\n",
    "    labels = []\n",
    "    words = []\n",
    "    for review in reviews:\n",
    "        rev = set(re.split(r'\\W+', review['review'].lower()))\n",
    "        rev = list(set(keys) & rev)\n",
    "        if len(rev):\n",
    "            words.append(rev)\n",
    "            labels.append(int(review[rating_type]>=14))    \n",
    "    indptr = [0]\n",
    "    indices = []\n",
    "    data = []\n",
    "    vocabulary = {}\n",
    "    for key in keys:\n",
    "        index = vocabulary.setdefault(key, len(vocabulary))\n",
    "    for rev in words:\n",
    "        for term in rev:\n",
    "            index = vocabulary.setdefault(term, len(vocabulary))\n",
    "            indices.append(index)\n",
    "            data.append(1)\n",
    "        indptr.append(len(indices))\n",
    "    return labels, csr_matrix((data, indices, indptr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, words = make_sparse_matrix(vocab, training[:10000], 'overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words.shape)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) *Logistic regression using Newtonâ€™s method*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val, val = make_sparse_matrix(vocab, validation[:10000], 'overall')\n",
    "labels_test, test = make_sparse_matrix(vocab, testing[:10000], 'overall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "lambdas = [10**float(x) for x in list(np.arange(-3, 10, 1))]\n",
    "lambdas = list(np.arange(17, 23, 1))\n",
    "best_lambda = 0\n",
    "best_error = 1e20\n",
    "for lam in lambdas:\n",
    "    print(lam)\n",
    "    lg = LogisticRegression(fit_intercept=True, C=1/lam, penalty='l2',\n",
    "                            multi_class='multinomial', solver='newton-cg',\n",
    "                            max_iter=10000)\n",
    "    model = lg.fit(words, labels)\n",
    "    predict = lg.predict(val)\n",
    "    error = np.mean(predict!=labels_val)\n",
    "    if error < best_error:\n",
    "        best_lambda = lam\n",
    "        best_error = error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Best lambda: 20\n",
      "Best error for validation: 24.307%\n"
     ]
    }
   ],
   "source": [
    "print('Validation:')\n",
    "print('Best lambda:', best_lambda)\n",
    "print('Best error for validation: %.3f%%'% (best_error*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for testing: 25.829%\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression(fit_intercept=True, C=1/best_lambda, penalty='l2',\n",
    "                        multi_class='multinomial', solver='newton-cg',\n",
    "                        max_iter=10000)\n",
    "model = lg.fit(words, labels)\n",
    "predict = lg.predict(test)\n",
    "error = np.mean(predict!=labels_test)\n",
    "print('Error for testing: %.3f%%'% (error*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lambdas = list(np.arange(10, 51, 1))\n",
    "best_lambdah = 0\n",
    "best_errorh = 1e20\n",
    "for lam in lambdas:\n",
    "    modelh = LinearSVC(loss='hinge', penalty='l2',\n",
    "                dual=True, tol=.0001, C = 1/lam).fit(words, labels)\n",
    "    predicth = modelh.predict(val)\n",
    "    error = np.mean(predicth!=labels_val)\n",
    "    if error < best_errorh:\n",
    "        best_lambdah = lam\n",
    "        best_errorh = error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Best lambda: 35\n",
      "Best error: 24.19%\n"
     ]
    }
   ],
   "source": [
    "print('Validation:')\n",
    "print('Best lambda:', best_lambdah)\n",
    "print('Best error: %.2f%%'% (best_errorh*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for testing: 26.41%\n"
     ]
    }
   ],
   "source": [
    "modelh = LinearSVC(loss='hinge', penalty='l2',\n",
    "            dual=True, tol=.0001, C = 1/best_lambdah).fit(words, labels)\n",
    "predicth = modelh.predict(test)\n",
    "errorh = np.mean(predicth!=labels_test)\n",
    "print('Error for testing: %.2f%%'% (errorh*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) *Stochastic gradient descent*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros((len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_into_batches(data, labels, n):\n",
    "    indices = [0] + [random.randint(1, data.shape[0]) for _ in range(n-1)] \\\n",
    "                + [data.shape[0]]\n",
    "    indices = sorted(indices)\n",
    "    batches = []\n",
    "    batches_lab = []\n",
    "    for i in range(len(indices)-1):\n",
    "        m = indices[i]\n",
    "        n = indices[i+1]\n",
    "        batches.append(data[m:n, :])\n",
    "        batches_lab.append(labels[m:n])\n",
    "    return batches, batches_lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have:\n",
    "$$ L(\\theta, \\lambda) = \\frac{1}{2} \\log \\left(1+e^{-2 y \\theta^Tx}\\right) + \\lambda \\|\\theta\\| $$\n",
    "$$ -G(y, x, \\theta)=\\frac{x y}{1+e^{2 y \\theta^Tx}} - 2\\lambda\\theta $$\n",
    "Therefore, our update is the following:\n",
    "$$ \\theta \\leftarrow \\theta + \\delta \\left(\\frac{x y}{1+e^{2 y \\theta^Tx}} - 2\\lambda\\theta\\right)  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_pass_update(batch, batch_lab, theta, n, lamb, delta):\n",
    "    m, n = batch.shape\n",
    "    for i in range(m):\n",
    "        x = batch[i]\n",
    "        y = batch_lab[i]\n",
    "        yhat = 1 / (1 + exp(-float(theta.dot(x))))\n",
    "        grad = (y - yhat) * yhat * (1 - yhat) * x\n",
    "        theta += delta*(grad - 2*lamb*theta)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One training epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def simulate_epoch(words, labels, theta, lam, delta, n):\n",
    "    random.seed(48)\n",
    "    batches, batches_lab = break_into_batches(words, labels, n)\n",
    "    for i in range(n):\n",
    "        if len(batches_lab[i]):\n",
    "            theta = sgd_pass_update(batches[i], batches_lab[i], theta, n, lam, delta)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(words, labels, theta, lam, delta, n, ite):\n",
    "    for i in range(ite):\n",
    "        theta = simulate_epoch(words, labels, theta, lam, delta, n)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train, train = make_sparse_matrix(vocab, training[:10000], 'overall')\n",
    "labels_val, val = make_sparse_matrix(vocab, validation[:6000], 'overall')\n",
    "labels_test, test = make_sparse_matrix(vocab, testing[:10000], 'overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_batches = 80\n",
    "lam = 1e-3\n",
    "delta = .01\n",
    "iterations = 10\n",
    "theta = np.zeros((len(vocab)))\n",
    "theta = SGD(train.toarray(), labels_train, theta, lam, delta, number_of_batches, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate: 29.51%\n"
     ]
    }
   ],
   "source": [
    "def get_error(theta, y, x):\n",
    "    m = len(y)\n",
    "    X=x\n",
    "    yhats = []\n",
    "    for i in range(m):\n",
    "        x = X[i]\n",
    "        yhats.append(1 / (1 + exp(-float(theta.dot(x)))))\n",
    "    yhat_class = [int(x > 0.5) for x in yhats]\n",
    "    error = []\n",
    "    for i in range(len(yhat_class)):\n",
    "        error.append(yhat_class[i]!=y[i])\n",
    "    return np.mean(error)\n",
    "print('Error rate: %.2f%%' % (get_error(theta, labels_val, val.toarray())*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_batches = 80\n",
    "lam = 1e-3\n",
    "ite = 10\n",
    "errors = []\n",
    "ran = [.0001, .001, .01, .1]\n",
    "for delta in ran:\n",
    "    thet = SGD(train.toarray()[:1000], labels_train[:1000],\n",
    "               theta, lam, delta, number_of_batches, ite)\n",
    "    errors.append((delta, get_error(theta, labels_test, test)))\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After several trials, it seems like a good regularisation parameter is: $\\lambda = 0.001$.\n",
    "\n",
    "let's see the error vs. iteration plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number_of_batches = 80\n",
    "lam = 1e-3\n",
    "delta = .01\n",
    "errors = []\n",
    "ran = range(1, 30, 2)\n",
    "for ite in ran:\n",
    "    thet = SGD(train.toarray()[:1000], labels_train[:1000],\n",
    "               theta, lam, delta, number_of_batches, ite)\n",
    "    errors.append(get_error(theta, labels_test, test))\n",
    "plt.plot(ran,errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$l(\\theta | X, y)=\\sum_{i=1}^{n}\\left[y_{i} x_{i}^{T} \\theta-\\log \\left(1+e^{x_{i}} \\theta\\right)\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a bit slower than logistic but still relatively fast to compute. The error rate is higher for SGD but still remains very close to logistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: *Scores versus text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([[rev['appearance'], rev['aroma'], rev['palate'],\n",
    "                 rev['style'], rev['taste']] for rev in brv])\n",
    "labels = 1*np.array([rev['overall']>14 for rev in brv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(brv)\n",
    "train = scores[:int(.7*L)]\n",
    "tr_labels = labels[:int(.7*L)]\n",
    "validation = scores[int(.7*L):int(.85*L)]\n",
    "val_labels = labels[int(.7*L):int(.85*L)]\n",
    "testing = scores[int(.85*L):]\n",
    "test_labels = labels[int(.85*L):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(fit_intercept=True, C=1/lam, penalty='l2',\n",
    "                        multi_class='multinomial', solver='newton-cg',\n",
    "                        max_iter=10000)\n",
    "model = lg.fit(scores[:100000], labels[:100000])\n",
    "predict = lg.predict(validation[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1667\n"
     ]
    }
   ],
   "source": [
    "print(np.mean([predict[i]!=(val_labels[:10000])[i] for i in range(len(predict))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_batches = 80\n",
    "lam = 1e-3\n",
    "delta = .01\n",
    "iterations = 10\n",
    "theta = np.zeros((5))\n",
    "theta = SGD(train[:10000], tr_labels[:10000], theta, lam, delta, number_of_batches, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate: 39.15%\n"
     ]
    }
   ],
   "source": [
    "print('Error rate: %.2f%%' % (get_error(theta, test_labels, testing)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores model predicts better. It is very difficult to obtain a good classification with words, and it makes more sense that people rate beers higher for their characteristics if they give it a high overall rating."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
